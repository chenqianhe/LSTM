{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNraNaPgj4UUxQKZ2QNApe2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chenqianhe/LSTM/blob/master/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMF9625Hrdoh",
        "colab_type": "code",
        "outputId": "c0fe55ff-2fe3-43e2-a69a-f9e4597d1617",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        }
      },
      "source": [
        "!pip install torch\n",
        "!pip install torchtext\n",
        "!python -m spacy download en\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchtext import data, datasets\n",
        "\n",
        "print('GPU: ', torch.cuda.is_available())\n",
        "\n",
        "torch.manual_seed(123)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.5.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (0.3.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.5.0+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext) (0.16.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.9)\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (47.1.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "GPU:  True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f377ab1ce90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYB6Bxr-sEIY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "dffd04f4-ff58-4b15-ee6e-ad9548f6ad04"
      },
      "source": [
        "TEXT = data.Field(tokenize='spacy')\n",
        "LABEL = data.LabelField(dtype=torch.float)\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz:   0%|          | 180k/84.1M [00:00<00:51, 1.63MB/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:01<00:00, 67.3MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_6OaqweFeqS",
        "colab_type": "code",
        "outputId": "e0077462-e2f1-4fc3-af2f-75f3d5286ed0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print('len of train data: ', len(train_data))\n",
        "print('len of test data: ', len(test_data))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len of train data:  25000\n",
            "len of test data:  25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji_KZBd0GWBY",
        "colab_type": "code",
        "outputId": "a4dd289c-0706-4c99-b80b-5059355370b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "print(train_data.examples[15].text)\n",
        "print(train_data.examples[15].label)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['An', 'unusually', 'straight', '-', 'faced', 'actioner', 'played', 'by', 'a', 'cast', 'and', 'filmed', 'by', 'a', 'director', 'who', 'obviously', 'took', 'the', 'material', 'seriously', '.', 'Imperfect', ',', 'as', 'is', 'to', 'be', 'expected', 'from', 'a', 'film', 'clearly', 'shot', 'on', 'a', 'tight', 'budget', ',', 'but', 'the', 'drama', 'is', 'involving--', 'it', \"'s\", 'one', 'of', 'those', 'films', 'that', 'when', 'it', 'gets', 'repeated', 'ad', 'nauseum', 'on', 'Cinemax', '2', 'or', 'More', 'Max', 'or', 'whatever', 'they', 'call', 'it', ',', 'you', 'end', 'up', 'watching', '40', 'minute', 'blocks', 'when', 'you', \"'re\", 'supposed', 'to', 'be', 'going', 'to', 'work', '.', 'Along', 'W/', '\"', 'Deathstalker', '2', '\"', ',', '\"', 'Chopping', 'Mall', '\"', ',', 'and', '\"', 'The', 'Assault', '\"', ',', 'a', 'reminder', 'that', 'Wynorski', 'is', 'a', 'much', 'more', 'talented', 'director', 'than', 'many', 'of', 'his', 'fellow', 'low', '-', 'budget', 'brethern', ',', 'who', 'has', 'a', 'real', 'ability', 'to', 'pace', 'a', 'genre', 'film', ',', 'when', 'he', 'actually', \"'s\", 'interested', 'in', 'the', 'material', '(', 'i.e.', ',', 'do', \"n't\", 'bother', 'watching', 'any', 'of', 'his', 'Shannon', 'Tweed', 'flicks', 'with', 'a', '3', 'or', 'a', '4', 'after', 'the', 'title', '!', ')', 'Actors', 'who', \"'ve\", 'had', 'too', 'little', 'to', 'do', 'recently', '(', 'Mancuso', ',', 'Ford', ',', 'even', 'Gary', 'Sandy', 'for', 'chrissakes', ')', 'really', 'put', 'their', 'all', 'into', 'some', 'of', 'their', 'best', 'roles', 'in', 'years', '--', 'as', 'for', 'Grieco', ',', 'he', 'has', 'the', 'right', 'look', ',', 'although', 'his', 'acting', 'is', 'a', 'bit', 'one', '-', 'note', '--', 'it', \"'s\", 'clear', 'his', 'character', 'is', 'supposed', 'to', 'be', 'self', '-', 'destructing', 'throughout', 'the', 'film', ',', 'but', 'Grieco', 'does', \"n't\", 'quite', 'convey', 'it', '.', 'I', 'checked', 'IMDB', 'and', 'I', 'see', 'the', 'writer', 'also', 'wrote', '\"', 'Sorority', 'House', 'Massacre', '2', '\"', '&', '\"', 'Dinosaur', 'Island', '\"', 'for', 'the', 'director', '--', 'both', 'minor', 'classics', 'in', 'their', 'own', 'rights', ',', 'but', 'obviously', '\"', 'silly', '\"', 'Roger', 'Cormon', '-', 'like', 'Cinema', '--', 'this', 'one', \"'s\", 'more', 'like', 'some', 'of', 'the', 'better', 'Jonathan', 'Demme', 'and', 'Jonathan', 'Kaplan', 'B', '-', 'pictures', 'of', 'the', '70', \"'s\", '--', 'giving', 'you', 'the', 'exploitation', 'element', 'but', 'offering', 'involving', 'drama', 'at', 'the', 'same', 'time', '--', 'a', 'real', 'step', 'forward', '.', 'Not', '\"', 'Citizen', 'Kane', ',', '\"', 'and', 'the', 'comic', 'final', 'moments', 'are', 'a', 'bit', 'disruptive', ',', 'but', 'a', 'well', '-', 'written', ',', 'character', '-', 'driven', 'above', '-', 'average', 'straight', '-', 'to', '-', 'video', 'actioner', '.', 'Small', 'achievements', 'like', 'this', 'should', 'not', 'be', 'overlooked', 'when', 'they', 'come', 'along', ',', 'which', 'is', 'rare', 'enough', '(', 'as', 'I', 'was', 'reminded', 'as', 'I', 'tried', 'to', 'sit', 'through', 'an', 'Albert', 'Pyun', 'monstrosity', 'called', '\"', 'Heatseeker', '\"', 'the', 'other', 'night', '--', 'this', 'low', '-', 'budget', 'stuff', 'is', \"n't\", 'as', 'easy', 'as', 'it', 'looks', '--', 'but', 'that', \"'s\", 'another', 'story', '!', ')']\n",
            "pos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYobSUihMrYb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "63406a8c-c4a7-4ad1-b9cb-74166c93d18d"
      },
      "source": [
        "TEXT.build_vocab(train_data, max_size=10000, vectors='glove.6B.100d')\n",
        "LABEL.build_vocab(train_data)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:25, 2.23MB/s]                          \n",
            "100%|█████████▉| 399186/400000 [00:14<00:00, 27060.30it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0MA6FCcxeHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batchsz = 80\n",
        "device = torch.device('cuda')\n",
        "train_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, test_data),\n",
        "    batch_size = batchsz,\n",
        "    device = device\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2i90oSwFGh2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "    super(Net, self).__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=2,\n",
        "                       bidirectional=True, dropout=0.5)\n",
        "    self.fc = nn.Linear(hidden_dim*2, 1)\n",
        "    self.dropout = nn.Dropout(0.5)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "\n",
        "    output, (hidden, cell) = self.rnn(embedding)\n",
        "\n",
        "    hidden = torch.cat([hidden[-2], hidden[-1]], dim=1)\n",
        "\n",
        "    hidden = self.dropout(hidden)\n",
        "    out = self.fc(hidden)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bEKLKs2Gk3B",
        "colab_type": "code",
        "outputId": "a8d2c193-c283-4b12-aa9c-07636c363d46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "rnn = Net(len(TEXT.vocab), 100, 256)\n",
        "\n",
        "pretrained_embedding = TEXT.vocab.vectors\n",
        "print(\"pretrained_embedding: \", pretrained_embedding.shape)\n",
        "rnn.embedding.weight.data.copy_(pretrained_embedding)\n",
        "print('embedding layer inited.')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pretrained_embedding:  torch.Size([10002, 100])\n",
            "embedding layer inited.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDAeAZOudCwd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "f63b4a05-fc2f-4211-ca46-db93bc90fcec"
      },
      "source": [
        "optimizer = optim.Adam(rnn.parameters(), lr=1e-3)\n",
        "criteon = nn.BCEWithLogitsLoss().to(device)\n",
        "rnn.to(device)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (embedding): Embedding(10002, 100)\n",
              "  (rnn): LSTM(100, 256, num_layers=2, dropout=0.5, bidirectional=True)\n",
              "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ND8NmfYKia2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(rnn, iterator, optimizer, criteon):\n",
        "  avg_acc = []\n",
        "  rnn.train()\n",
        "\n",
        "  for i, batch in enumerate(iterator):\n",
        "    pred = rnn(batch.text).squeeze(1)\n",
        "    loss = criteon(pred, batch.label)\n",
        "    acc = binary_acc(pred, batch.label).item()\n",
        "    avg_acc.append(acc)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4oVHHL4LS94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def binary_acc(preds, y):\n",
        "  preds = torch.round(torch.sigmoid(preds))\n",
        "  correct = torch.eq(preds, y).float()\n",
        "  acc = correct.sum()/len(correct)\n",
        "  return acc\n",
        "\n",
        "def eval(rnn, iterator, criteon):\n",
        "  avg_acc = []\n",
        "  rnn.eval()\n",
        "  with torch.no_grad():\n",
        "    for batch in iterator:\n",
        "      pred = rnn(batch.text).squeeze(1)\n",
        "      loss = criteon(pred, batch.label)\n",
        "      acc = binary_acc(pred, batch.label).item()\n",
        "      avg_acc.append(acc)\n",
        "  avg_acc = np.array(avg_acc).mean()\n",
        "  print('>>test : ', avg_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hanxHwRsqIAg",
        "colab_type": "code",
        "outputId": "6e93952e-546c-45da-92c8-6ac87faab57d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "\n",
        "for epoch in range(10):\n",
        "  eval(rnn, test_iterator, criteon)\n",
        "  train(rnn, train_iterator, optimizer, criteon)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>test :  0.4998402637652696\n",
            ">>test :  0.6479632693548172\n",
            ">>test :  0.6702875513047837\n",
            ">>test :  0.866932919421516\n",
            ">>test :  0.8763179030662147\n",
            ">>test :  0.8869808428584577\n",
            ">>test :  0.8875798842015739\n",
            ">>test :  0.8851437821936684\n",
            ">>test :  0.8819888317927765\n",
            ">>test :  0.8856230155347635\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}